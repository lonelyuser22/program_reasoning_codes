from mpi4py import MPI
comm = MPI.COMM_WORLD

rank = comm.Get_rank()
print("My rank is: ", rank)

if rank ==0:
    data1 = 100000
    dest_prc = 4
    
    comm.send(data1, dest=dest_prc)    # 0 1 2 3 4
    print("sending data %d " %data1 + "to process %d" %dest_prc)


if rank ==1:
    data2 = "hello"
    dest_prc=8       # 0 1 2 3 4 5 6 7 8

    comm.send(data2, dest=dest_prc)
    print("sending data %s " %data2 + "to process %d" %dest_prc)


if rank == 4:
    data1 = comm.recv(source=0)
    print("data received is: %d "%data1)

if rank == 8:
    data2 = comm.recv(source=1)
    print("data received is: %s" %data2)

##########

# send() and recv() are blocking calls.
#When you call send(), the calling process doesn't proceed to the next line of code until the message has been successfully copied into the communication buffer and the process is notified that the message can be safely transmitted to the receiving process.
#Similarly, recv() blocks the calling process until a message with the specified tag (identifier) from the expected source (rank) is received and copied into the memory allocated by the user.

#non-blocking calls

from mpi4py import MPI
comm = MPI.COMM_WORLD

rank = comm.Get_rank()

if rank ==0:
    data = {'a':7, 'b':3.14}
    req = comm.isend(data, dest=1, tag=10)
    req.wait()  # blocking call waiting for a non-blocking call to complete.

elif rank ==1:
    data = None
    print('Before receiving: ', data)

    req = comm.irecv(source=0, tag=10)
    print('After receiving: ', data)

    data = req.wait()
    print('After waiting: ', data)




###############3

from mpi4py import MPI
import numpy as np

comm = MPI.COMM_WORLD
rank = comm.Get_rank()

if rank == 0:
    data = np.arange(1000, dtype='i')
    comm.Send(data, dest=1)

elif rank == 1:
    data = np.empty(1000, dtype='i')
    comm.Recv(data, source=0)
    print("Received data:", data)


#############

from mpi4py import MPI
comm=MPI.COMM_WORLD

p=MPI.Wtime()       #3 processes: code runs 3 times -> 0, 1, 2

print("Message")

q=MPI.Wtime()

ts=q-p   
print(ts)

##########################

#We need the starting time (x) captured before sending the message to accurately measure
# the parallel time for the sending operation. 
#It doesn't depend on the rank, so it's placed at the beginning.
#The ending time (y) needs to be recorded after the message is sent on process 0. 
# Since this action happens within the if block for process 0, y is calculated there.

x=MPI.Wtime()           #3 processes: code runs 3 times -> 0, 1, 2
rank=comm.Get_rank()

if rank==0:
    #a={'Jan':1, 'Feb':2}
    comm.send("Hi", dest=1, tag=1)
    #comm.send(a, dest=2)

    #received by process having rank 1

    y=MPI.Wtime()
    tp=y-x            # time = endtime = starttime
    print(tp)


    sp=ts/tp          # speedup = time(series) / time(parallel)
    eff_percentage=sp/2  *100    # (speedup / no. of processes) x100%    
    print("Speed up factor ", sp)
    print("Efficiency ", eff_percentage)


# if endtime were here --> series not parallel

if rank==1:
    b=comm.recv(source=0, tag=1)
    print("The received message at process 1 is %s"%b)


#if rank==2:
#    c=comm.recv(source=0)
#    print("received from process 0" ,c)


#####################

from mpi4py import MPI
comm = MPI.COMM_WORLD

rank  = comm.Get_rank()

if rank==1:
   data_send= "a"
   destination_process = 5
   source_process = 5

   #data_received=comm.recv(source=source_process)
   #comm.send(data_send,dest=destination_process)
   data_received=comm.sendrecv(data_send,dest=destination_process,source =source_process)

   print("Data sent is: %s" %data_send)
   print("Data received is: %s" %data_received)


if rank==5:
   data_send= "b"
   destination_process = 1
   source_process = 1

   #comm.send(data_send,dest=destination_process)
   #data_received=comm.recv(source=source_process)
   data_received=comm.sendrecv(data_send,dest=destination_process,source=source_process)

   print("Data sent is: %s" %data_send)
   print("Data received is: %s" %data_received)


####################

# LAB2 Q1	
#Create a system with 3 processes, 
#where the master process reads a list (of integers) and prints the sum. 
# It sends the list to the processes 2 and 3
# with 2 finding and printing the sum of even elements in the list 
# and 3 printing the sum of the odd elements in the list. 

from mpi4py import MPI
comm = MPI.COMM_WORLD

rank = comm.Get_rank()

# input("enter a number") 
# .split() string --> splits into individual elements in a list


if rank == 0:
    input_string = input("Enter a list of integers separated by spaces: ") # "1 2 3 4 5" 
    # Split the input string by spaces and convert each element to integer
    list_int = [int(x) for x in input_string.split()] #   ["1","2","3","4"] --> [1,2,3,4]
    print("List entered: ", list_int)

    sum = 0
    
    for i in list_int:
        sum = sum + i
    print("The sum of all the elements is: ",sum)

    comm.send(list_int, dest=2)
    comm.send(list_int, dest=3)

if rank == 2:
    list_int = comm.recv(source=0)
    even_sum = sum (num    for num in list_int     if num % 2 == 0)
    print("The sum of all the even numbers is: ",even_sum)

if rank == 3:
    list_int = comm.recv(source=0)
    odd_sum = sum( num          for num in list_int      if num%2 != 0)
    print("The sum of all the odd elements is: ",odd_sum)

    
#############

# LAB2 Q2
#The master process sends a string to the child processes 2 and 3. 
#The child process 2 prints the vowels in the string while the 
#process 3 prints the consonants in the string.

from mpi4py import MPI
comm = MPI.COMM_WORLD

rank = comm.Get_rank()

if rank == 0:
    inp_string = input("Enter a string ")

    comm.send(inp_string, dest=2)
    comm.send(inp_string, dest=3)

if rank == 2:
   inp_string = comm.recv(source=0)
   
   vowels = [char for char in inp_string if char.lower() in 'aeiou']
   print("Vowels: ", vowels)

if rank == 3:
    inp_string = comm.recv(source=0)
    
    consonants = [char for char in inp_string if char.lower() not in 'aeiou']
    print("Consonants: ",consonants)


##############

# LAB2 Q3    
#Consider a system of 2 processes. 
#The master process generates an array of random numbers of size n. 
#It shares the array with the slave. Slave is asked to do the sum of numbers. 
#The result returned by the slave is printed by the master process. 
#The master process is simultaneously counting and printing the numbers less than 50 in the array.

from mpi4py import MPI
comm = MPI.COMM_WORLD
import random

rank = comm.Get_rank()

if rank == 0:
    
    print("In the master process.")

    n = int(input("Enter the desired list size (number of elements): "))
    
    arr = [] 
    for i in range (n):
        arr.append(random.randint(1,100))

    #  [OR]   data = np.random.randint(1, 100, size=n)  

    print("The array is: ",arr)
    comm.send(arr,dest=1)
    
    from_slave = comm.recv(source=1)
    print("The sum obtained by the slave process is: ",from_slave)

    counter = 0
    print("The elements lesser than 50 are: ")
    for i in arr:
        if i<50:
            print(i)
            counter+=1
    print("The no. of elements lesser than 50 are: ", counter)
    

    # [OR]     less = len(data[data < 50])  
    #          print(f"Master process {less}")


if rank == 1:
    print("In the slave process.")
    
    arr = comm.recv(source=0)
    sum = sum(arr)

    comm.send(sum,dest=0)

###############

from mpi4py import MPI
comm = MPI.COMM_WORLD

size = comm.Get_size()
rank = comm.Get_rank()

data = (rank+1) **2
data = comm.gather(data, root=0)

if rank == 0:
   for i in range(1,size):
      value_rec = data[i]
      print(" process %s receiving %s from process %s" %(rank , value_rec , i))
   
   print("The full array gathered =", data)



#########################

import numpy as np
from mpi4py import MPI
comm = MPI.COMM_WORLD

size = comm.size
rank = comm.rank

array_size = 3

recvdata = np.zeros(array_size,dtype=int)
senddata = (rank+1) * np.arange(array_size,dtype=int)   # rank * [1,2,3] for 3 processes
print(" process %s sending %s " %(rank , senddata))
comm.Reduce(senddata,recvdata,root=0,op=MPI.SUM)

# Print on all processes, but formatted nicely for root process
if rank == 0:
    print('\nat process 0, after Reduce: data =', recvdata)


#######################

from mpi4py import MPI
import numpy
comm = MPI.COMM_WORLD

size = comm.Get_size()
rank = comm.Get_rank()

a_size = 1
senddata = (rank+1)*numpy.arange(size,dtype=int)
recvdata = numpy.empty(size*a_size,dtype=int)

comm.Alltoall(senddata,recvdata)
print(" process %s sending %s receiving %s"%(rank , senddata , recvdata))


######################

# LAB3 Q1	
#x being the size of the array held by the master process, which is initially empty. 
#Create n processes in an environment where each process generates an array of size x/n, 
#Each slave is generating the numbers and sending them to the master. 
#Master gathers them in an array and prints the count of elements which are multiples of 5. 
#The random numbers can be between 1 and 1000.


## 1. Create n processes in an environment where each process generates an array of size x/n, x being the size of the array held by the master process, which is initially empty. Each slave is generating the numbers and sending them to the master. Master gathers them in an array and prints the count of elements which are multiples of 5. The random numbers can be between 1 and 1000.

from mpi4py import MPI
import numpy as np 
comm = MPI.COMM_WORLD
size = comm.Get_size()
rank = comm.Get_rank()
#run w 6 processes ADJUST

x=100
n_new = (x//size)
if n_new%2==0:
    n_new+=2
data = np.random.randint(1,1000, n_new+1)
data = comm.gather(data, root=0)

if rank == 0:
    print ("rank = %s " %rank + "...receiving data from other process")
    big_arr = []
    for i in range(1,size):
        value = data[i]
        value=list(value)
        for val in value:
            big_arr.append(val)
        print(" process %s receiving %s from process %s" %(rank , value , i))

    print("The merged array =", big_arr)
    count = 0
    for num in big_arr:
        if num%2==0:
            count += 1
    print("The count =", count)

'''
[OR]

from mpi4py import MPI
import numpy as np

comm = MPI.COMM_WORLD

rank = comm.Get_rank()
size = comm.Get_size()

#master process
if rank == 0:
    x = 1000
    arraySizePerProcess = x // size
    masterArray = np.empty(x, dtype=int)    # setting up an empty array 
    counts = 0

    # gather data from all processes
    gatheredData = comm.gather(None, root = 0)

    # gather all the collected data into the master array 
    for i in range(1, size):
        recvBuff = gatheredData[i]

        # to set a start and end index for the array that is received
        startIndex = (i - 1) * arraySizePerProcess
        endIndex = i * arraySizePerProcess

        # to set the recvBuff to master array 
        masterArray[startIndex:endIndex] = recvBuff

        counts = np.sum(masterArray % 5 == 0)
        print("The numbers that are divisible are by 5 are: ", counts)

else:
    x = 1000
    arraySizePerProcess = x // size
    localArray = np.random.randint(1, 1001, arraySizePerProcess)

    comm.gather(localArray, root = 0)


        





'''









'''
[OR]

from mpi4py import MPI 
import numpy as np 
comm = MPI.COMM_WORLD 
rank = comm.Get_rank() 
size = comm.Get_size() 

mrank = 0 
asize = 179 
ssize = asize // size   

if rank == mrank: 
    marray = np.empty(asize, dtype=int)   
else: 
    marray = None 

ssizes = comm.scatter([ssize] * size, root=mrank) 

if rank != mrank: 
    larray = np.random.randint(1, 1001, ssizes)   
    comm.send(larray, dest=mrank) 
if rank == mrank: 
    for i in range(1, size): 
        rarray = comm.recv(source=i) 
        marray[(i * ssize):((i + 1) * ssize)] = rarray 
    print("Master process ") 
    count = np.sum(marray % 5 == 0) 
    print("Count ", count) 
else: 
    comm.send(None, dest=mrank)





'''



##################

# LAB3 Q2
#Create an environment with n processes. 
#The master process generates random numbers of size 1000. 
#The range of random numbers is between 1 and 50. 
#All the even numbered slaves excluding the master is finding the sum of even numbers in the array. 
#All the odd numbered processes are finding the sum of odd elements in the array. 
#They divide the work equally among them to find the sum. 
#The even sum and odd sum are finally added by the master process which displays the final output. 
#Use appropriate routines for effective transmission of data.

#hardcoded

from mpi4py import MPI
import numpy as np

comm = MPI.COMM_WORLD

rank = comm.Get_rank()
size = comm.Get_size()

n = 10

# master process
if rank == 0:

    numbers = np.random.randint(1, 10, n)  
    print("Generated numbers:", numbers)

    
    for i in range(1, size):
        comm.Send(numbers, dest=i)

    totalEvenSum = 0
    totalOddSum = 0

    for i in range(1, size):
        if i % 2 == 0:
            totalEvenSum += comm.recv(source=i, tag = 1)
        else:
            totalOddSum += comm.recv(source=i, tag = 11)

    print("The sum of even elements are: ", totalEvenSum)
    print("The sum of odd elements are: ", totalOddSum)

# child process
else:
    
    recvNum = np.empty(n, dtype=int)
    comm.Recv(recvNum, source=0)

    evenSum = 0
    oddSum = 0

    if rank % 2 == 0:
        for i in range(len(recvNum)):
            if recvNum[i] % 2 == 0:
                evenSum += recvNum[i]
    else:
        for i in range(len(recvNum)):
            if recvNum[i] % 2 != 0:
                oddSum += recvNum[i]

    print("Even sum for process: ", evenSum)
    print("Odd sum for process: ", oddSum)
    comm.send(evenSum, dest=0, tag = 1)
    comm.send(oddSum, dest=0, tag = 11)


'''

[OR]

from mpi4py import MPI
import random
comm = MPI.COMM_WORLD
rank = comm.Get_rank()
size = comm.Get_size()
x = 1000
lsize = x // size
larray = []
for _ in range(lsize):
 larray.append(random.randint(1, 50))
garray = comm.gather(larray, root=0)
if rank == 0:
 farray = [num for sublist in garray for num in sublist]
 even = [num for num in farray if num % 2 == 0]
 odd= [num for num in farray if num % 2 != 0]
 esum = sum(even)
 osum = sum(odd)
 print(f"The even sum is:{esum}")
 print(f"The odd sum is: {osum}")
 print(f"The total sum is: {esum + osum}")



'''

#################

# LAB3 Q3
#For simplicity, consider that a system contains even number of processes n. 
#Create an environment where process numbered 0 pairs up with process numbered n-1, 
#process numbered 1 with n-2 etc. 
# The pairs exchange messages between each other. 
#In each pair, the odd numbered process sends a random number (between 1 and 100) 
#and the even numbered process in the pair finds the square of the number received and sends the result to the sender. 
#The received value is printed by the process.

# if size = 4 ==> ranks: 0,1,2,3 ==> 0 paired with 3, 1 paired with 2


from mpi4py import MPI
import numpy as np
import random

comm = MPI.COMM_WORLD

rank = comm.Get_rank()
size = comm.Get_size()

if size %2 == 0:
        if rank%2!=0:
            pair = size-rank-1   # For ex: 0 paired with: n-1 = n - 0 - 1  
                                            # n - 1 paired with: n - (n-1) - 1 = 0  

            print("Odd rank:", rank)
            x=random.randint(1,100)
            print("Rand number to be sent:", x)

            comm.send(x, dest=pair)  

            res=comm.recv(source=pair)

            
            print("Result: %d" %res + " received from even pair process %d" %pair )


        else:
            data=comm.recv(source=size-rank-1)    # 0 --> receives randint from 3
            comm.send(data*data, dest=size-rank-1)  # sends square back to 3


#################

# LAB4 Q1.a
#The number n may be even or odd but is a positive constant. Compute n! using 
#2 concurrent processes, each computing approximately half of the complete sequence. 
# A master process then combines the two partial results.

#assess their performance in terms of speed up factor. (LAB4 Q1.a and LAB4 Q1.b)

from mpi4py import MPI
comm = MPI.COMM_WORLD
import time
import numpy as np

size = comm.Get_size()
rank = comm.Get_rank()

if rank == 0:
    n = int(input("Enter a number: "))
else:
    n = None

# Broadcast the value of n to all processes
n = comm.bcast(n, root=0)
def compute_factorial(n):
    if n == 0:
        return 1
    else:
        return n * compute_factorial(n - 1)
start=MPI.Wtime()


if rank == 0:
        
        arr = []
        for i in range(1, n+1):
            arr.append(i)

        mid = len(arr) // 2  # Calculate the midpoint of the array.
        first_half = arr[:mid]  # First half of the array from index 0 to mid-1
        second_half = arr[mid:]  # Second half of the array from index mid to the end

        comm.send(first_half,dest=1)
        comm.send(second_half,dest=2)


        comp1 = comm.recv(source=1)
        comp2 = comm.recv(source=2)

        final_result = comp1 * comp2
        print("Factorial is:", final_result)


if rank == 1:
    received_half1=comm.recv(source=0)
    prod1 = np.prod(received_half1)

    comm.send(prod1,dest=0)


if rank == 2:
    received_half2=comm.recv(source=0)
    prod2 = np.prod(received_half2)

    comm.send(prod2,dest=0)

end=MPI.Wtime()
tp=end-start
print("Parallel time: " ,tp)

ts=compute_factorial(n)
print("Serial time: " ,ts)

speedup=ts/tp
print("Speedup factor= ",speedup)
      
#####################

# LAB4 Q1.b
# Write parallel programs to Compute n! using a producer and consumer process connected. 
# The producer produces the numbers 1, 2, 3… n in a sequence. 
# The consumer accepts the sequence of numbers from the producer and 
# accumulates the result (i.e.) 1x2x3…


#assess their performance in terms of speed up factor. (LAB4 Q1.a and LAB4 Q1.b)

from mpi4py import MPI
comm = MPI.COMM_WORLD
import time

size = comm.Get_size()
rank = comm.Get_rank()

if rank == 0:
    n = int(input("Enter a number: "))
else:
    n = None

# Broadcast the value of n to all processes
n = comm.bcast(n, root=0)

def compute_factorial(n):
    if n == 0:
        return 1
    else:
        return n * compute_factorial(n - 1)
    

start=MPI.Wtime()
if rank == 0:
    arr = list(range(1, n + 1))
    for i in arr:
        comm.send(i, dest=1)

    total_product = comm.recv(source=1)
    print("Factorial of the number", n, "is =", total_product)

elif rank == 1:
    p = 1  # Initialize product variable
    for _ in range(1, n + 1):
        d = comm.recv(source=0)
        print("Received:", d)
        p *= d  # Update product with received number

    comm.send(p, dest=0)
end=MPI.Wtime()

tp=end-start
print("Parallel time: " ,tp)
ts=compute_factorial(n)
speedup=ts/tp
print("Speedup factor= ", speedup)


#####################

# LAB4 Q2

#You have been given a data set represented as a nxn matrix. 
#The target is to add all the elements of the matrix using parallel computation. 
#There are P processors which can perform the computation parallelly.  

#Assume that the master process holds the input matrix and 
#it sends smaller matrices to P slaves to do the computation. 
#Each slave performs the addition of smaller matrices and sends the result to the master. 
#The master adds up all the results to get the final sum. 

from mpi4py import MPI
import numpy as np

comm = MPI.COMM_WORLD
rank = comm.Get_rank()
size = comm.Get_size()

# Define the size of the matrix
n = 5

# Initialize the input matrix in the master process
if rank == 0:
    matrix = np.random.randint(1, 10, size=(n, n))  # Generate a random matrix
    print("Original Matrix:")
    print(matrix)

    # Scatter the matrix to all processes
    local_matrix = np.array_split(matrix, size, axis=0)
else:
    local_matrix = None

# Scatter the matrix to all processes
local_matrix = comm.scatter(local_matrix, root=0)

# Compute the sum of elements in the local matrix
local_sum = np.sum(local_matrix)

# Reduce all local sums to get the global sum
global_sum = comm.reduce(local_sum, op=MPI.SUM, root=0)

# Master process prints the final sum
if rank == 0:
    print("Total Sum:", global_sum)

'''
[OR]

from mpi4py import MPI
import random
import numpy as np
comm=MPI.COMM_WORLD
rank=comm.Get_rank()
size=comm.Get_size()
if rank == 0:
    n = int(input("Enter a number: "))
else:
    n = None
n = comm.bcast(n, root=0)
if rank == 0:
    matrix = np.random.randint(1, 10, size=(n, n))
else:
    matrix = None

# Broadcast the matrix to all processes
matrix = comm.bcast(matrix, root=0)
print("MAtrix: ", matrix)
local= np.empty((n), dtype=int)
comm.Scatter(matrix, local, root=0)
print("Local matrix: ",local)
localsum=sum(local)
print("Local sum: ", localsum)
tot=comm.reduce(localsum, op=MPI.SUM, root=0)
if rank==0:
    print("Total sum = ",tot)

'''


###################

# LAB4 Q3
#You have an image which has to be relocated from (0,0) to (10, 10) and also 
#rotated to an angle of 30 degrees. You are using p processes to do the task 
#using a row major division. Perform the task using embarrassingly parallel computation 
#where the slaves update the new computed data to the master and 
#the master just overwrites the updated data to the array maintained. 
#The slaves just compute the new values and display it on the screen. 
#Print the speed up factor and efficiency.

from mpi4py import MPI
import math
comm = MPI.COMM_WORLD
rank = comm.Get_rank()
size = comm.Get_size()
image = [
    [100, 110, 120],
    [130, 140, 150],
    [160, 170, 180],
]
height = len(image)
width = len(image[0])
new_x = 10
new_y = 10
rotation_angle = 30 * math.pi / 180
if size < 2:
    raise ValueError("This program requires at least 2 processes to run!")
if rank == 0:
    rows_per_process = (height + size - 1) // size
    start_rows = [i * rows_per_process for i in range(size)]
    end_rows = [min((i + 1) * rows_per_process, height) for i in range(size)]
    for i in range(1, size):
        comm.send([image[start_rows[i]:end_rows[i]], new_x, new_y, rotation_angle], dest=i)
    rotated_image = relocate_and_rotate(image[:start_rows[1]], new_x, new_y, rotation_angle)
    for row in rotated_image:
        print(row)
else:
    received_data = comm.recv(source=0)
    sub_image, new_x, new_y, rotation_angle = received_data
    rotated_sub_image = relocate_and_rotate(sub_image, new_x, new_y, rotation_angle)
    for row in rotated_sub_image:
        print(row)
def relocate_and_rotate(sub_image, new_x, new_y, rotation_angle):
    rotated_sub_image = []
    for row in sub_image:
        new_row = []
        for pixel_value in row:
            new_x_coord = pixel_value[0] + new_x
            new_y_coord = pixel_value[1] + new_y
            cos_theta = math.cos(rotation_angle)
            sin_theta = math.sin(rotation_angle)
            new_x_coord_rotated = new_x_coord * cos_theta - new_y_coord * sin_theta
            new_y_coord_rotated = new_x_coord * sin_theta + new_y_coord * cos_theta
            if 0 <= new_x_coord_rotated < width and 0 <= new_y_coord_rotated < height:
                new_row.append((int(new_x_coord_rotated), int(new_y_coord_rotated)))
        rotated_sub_image.append(new_row)
    return rotated_sub_image


###############################3

# LAB5 Q1
#Assume that you are finding the sum of ‘n’ numbers using 8 CPUs. 
#The numbers are held by the master process P0 and the task is 
#assigned using binary divide and conquer approach. 
#The processes divide the numbers and find the partial sum. 
#The final sum is conquered at each level and the result is printed by the master process. 

from mpi4py import MPI
comm = MPI.COMM_WORLD
rank = comm.Get_rank()
size = comm.Get_size()
if size < 2:
    raise ValueError("This program requires at least 2 processes to run!")
if rank == 0:
    n = int(input("Enter the number of elements: "))
    if n % 8 != 0:
        print(f"Warning: Number of elements ({n}) is not divisible by 8. Results might be inaccurate.")
    numbers = [i for i in range(n)]
    chunk_size = n // size
    for i in range(1, size):
        start_index = i * chunk_size
        end_index = min((i + 1) * chunk_size, n)
        comm.send(numbers[start_index:end_index], dest=i)
    local_sum = sum(numbers[:chunk_size])
    for i in range(1, size):
        received_sum = comm.recv(source=i)
        local_sum += received_sum
    print(f"Sum of {n} elements: {local_sum}")
else:
    received_numbers = comm.recv(source=0)
    partial_sum = sum(received_numbers)
    comm.send(partial_sum, dest=0)

##############

#LAB 5 Q2
#Sort the given ‘n’ numbers using bucket sort and portioning approach 
#The numbers falling into a single bucket are sorted using the inbuilt sort() function. 
#The numbers are initially with the master and the numbers are broadcasted. 
#There are 10 processors numbered 0 to 9 who store the numbers in each bucket 
#based on the digit. Assume the number of digits in the input is to a maximum of 3.

from mpi4py import MPI
import random
comm = MPI.COMM_WORLD
rank = comm.Get_rank()
size = comm.Get_size()
if size < 2:
    raise ValueError("This program requires at least 2 processes to run!")
num_digits = 3
if rank == 0:
    n = int(input("Enter the number of elements to sort: "))
    numbers = [random.randint(10**i, 10**(i+1) - 1) for i in range(num_digits)] * (n // size + 1)
    random.shuffle(numbers)
    comm.Bcast(numbers, root=rank)
start_time = MPI.Wtime()  
bucket_size = 10 // size
buckets = [[] for _ in range(size * 10)]
digit_to_process = (rank // bucket_size) % 10  
for num in numbers:
    least_sig_digit = num % 10
    bucket_index = digit_to_process * 10 + least_sig_digit
    buckets[bucket_index].append(num)
sorted_buckets = comm.gather(buckets, root=0)
if rank == 0:
    sorted_numbers = []
    for bucket in sorted_buckets:
        sorted_numbers.extend(sorted(bucket))
    print(f"Sorted numbers: {sorted_numbers}")
    end_time = MPI.Wtime()
    total_time = end_time - start_time
    print(f"Total execution time: {total_time:.4f} seconds")
else:
    for bucket in buckets:
        bucket.sort()
